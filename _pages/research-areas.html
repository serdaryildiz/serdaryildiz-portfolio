---
layout: archive
permalink: /research-areas/
---

<style>
.research-areas {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 2rem;
  margin-bottom: 2rem;
}

.area {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  background-color: #ffffff;
  padding: 1rem;
  border-radius: 8px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  transition: transform 0.2s ease, box-shadow 0.2s ease;
  text-decoration: none !important;
  color: inherit !important;
}

.area:hover {
  transform: scale(1.05);
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
}

.area p {
  margin: 0;
  font-size: 1.1rem;
  font-weight: 500;
  color: #4B6D93;
}

.icon {
  font-size: 2rem;
  color: #4B6D93;
}

.subsection {
  margin-bottom: 2rem;
}

.subsection h3 {
  color: #4B6D93;
  font-size: 1.5rem;
}

.subsection p {
  font-size: 1rem;
  color: #607080;
  line-height: 1.5;
}

.research-areas img,
.subsection img {
  width: auto;
  height: 20rem; /* Fixed height */
  object-fit: cover; /* Ensures the image fills the area, cropping if necessary */
  border-radius: 8px; /* Keeps the rounded corners */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
}

</style>

<h1>Research Areas</h1>

<div class="research-areas">
  <a href="#person-reid" class="area">
    <span class="icon">üë§</span>
    <p>Person Re-Identification</p>
  </a>
  <a href="#geo-localization" class="area">
    <span class="icon">üåç</span>
    <p>Geo-Localization</p>
  </a>
  <a href="#scene-text-recognition" class="area">
    <span class="icon">üìù</span>
    <p>Scene Text Recognition</p>
  </a>
  <a href="#image-captioning" class="area">
    <span class="icon">üñºÔ∏è</span>
    <p>Image Captioning</p>
  </a>
  <a href="#mitosis-detection" class="area">
    <span class="icon">üß¨</span>
    <p>Mitosis Detection</p>
  </a>
  <a href="#nuclei-instance-segmentation" class="area">
    <span class="icon">üî¨</span>
    <p>Nuclei Instance Segmentation</p>
  </a>
  <a href="#semi-supervised-learning" class="area">
    <span class="icon">üìö</span>
    <p>Semi-Supervised Learning</p>
  </a>
</div>

<div class="subsection" id="person-reid">
    <h3>Person Re-Identification</h3>
    <div class="research-area">
      <div class="subsection-image">
        <img src="../research-areas/reid.png" alt="Person Re-Identification" >
      </div>
      <div class="research-area-info">
        <p>
          Person Re-Identification (ReID) focuses on the task of matching individuals across multiple images or camera views. 
          Despite significant advancements in deep learning, existing ReID models often struggle to generalize effectively 
          beyond their training environments due to domain shifts, variations in lighting, camera angles, and occlusions.
        </p>
        <p>
          My research is dedicated to addressing these challenges by developing models that emphasize robust generalization, 
          making them more adaptable to real-world scenarios. This includes techniques such as improving feature 
          representations, leveraging domain adaptation methods, and enhancing the robustness of models to unseen variations.
        </p>
        <p>
          The ultimate goal is to bridge the gap between laboratory results and real-world applications, enabling practical 
          implementations in areas.
        </p>
      </div>
    </div>
  </div>
  

  <div class="subsection" id="geo-localization">
    <h3>Geo-Localization</h3>
    <div class="subsection-image">
        <img src="../research-areas/geo-localization.png" alt="Geo-Localization">
    </div>
    <p>
      Geo-localization is a critical area in computer vision that focuses on determining the geographical location of an image. My research aims to address the challenges in visual place recognition (VPR), including variations in lighting, weather, and seasonal changes, as well as the limitations of GPS in certain scenarios like autonomous navigation in space or disaster areas. 
    </p>
    <p>
      Traditional datasets often lack dense coverage or fail to represent the diverse real-world conditions effectively. I work on developing solutions that leverage high-resolution visual data paired with precise location metadata to bridge these gaps. My goal is to enhance the generalization and robustness of VPR models, enabling them to perform consistently under varying conditions.
    </p>

  </div>
  

  <div class="subsection" id="scene-text-recognition">
    <h3>Scene Text Recognition</h3>
    <div class="subsection-content">
      <div class="subsection-image">
        <img src="../research-areas/STR.jpg" alt="Scene Text Recognition">
      </div>
      <div class="subsection-text">
        <p>
          Scene Text Recognition (STR) focuses on extracting textual information embedded within natural scene images, playing a vital role in applications like document analysis, and automated translation systems. Despite its importance, STR remains a challenging task due to the diversity of text styles, orientations, and backgrounds in real-world images.
        </p>
        <p>
          My work in STR aims to address several key challenges: improving the recognition of irregular and non-horizontal text arrangements, enhancing the handling of noisy, low-resolution images, and developing methods that generalize across languages. Current models often struggle with linguistic variations, diacritic characters, and diverse font styles, making them less applicable to non-English languages or real-world conditions.
        </p>
        <p>
          To tackle these issues, my research emphasizes the creation of robust datasets and advanced models capable of handling multi-language text, diverse fonts, and environmental conditions. This includes exploring novel synthetic data generation techniques and innovative recognition architectures tailored for scene text's unique challenges.
        </p>
      </div>
    </div>
  </div>

  <div class="subsection" id="image-captioning">
    <h3>Image Captioning</h3>
    <div class="research-area">
        <div class="subsection-image">
            <img src="../research-areas/captioning.png" alt="Image Captioning">
        </div>
        <div class="research-area-info">
            <p>
                Image captioning involves generating descriptive text for images, enabling machines to interpret and describe visual data. This technology is crucial for applications such as assistive tools, autonomous systems, and image-based search engines.
            </p>
            <p>
                My research particularly focuses on challenges like the lack of annotated datasets for underrepresented languages, including Turkish, noisy image contexts, and linguistic diversity. Using advanced techniques such as vision transformers and text decoders, I aim to enhance the capabilities of image captioning models to support the Turkish language alongside others.
            </p>
            <p>
                By addressing these challenges, my work contributes to developing models that generate syntactically accurate and contextually meaningful captions, making them more versatile and applicable to diverse real-world scenarios.
            </p>
        </div>
    </div>
</div>



<div class="subsection" id="mitosis-detection">
    <h3>Mitosis Detection</h3>
    <div class="subsection-content">
        <div class="subsection-image">
            <img src="../research-areas/mitosis-det.png" alt="Mitosis Detection">
        </div>
        <div class="subsection-text">
            <p>
                Mitosis detection is crucial in the field of digital pathology, as it plays a vital role in diagnosing and prognosing cancer. This task involves identifying mitotic cells within histopathological images, which is challenging due to the high variability in cell morphology, overlapping cells, and the presence of cells that mimic mitotic features.
            </p>
            <p>
                My research focuses on addressing these challenges by developing robust and generalizable models. Key objectives include reducing false positives, tackling domain shift caused by variations in scanners, staining protocols, and tissue types, and ensuring high performance on out-of-domain datasets.
            </p>
            <p>
                Utilizing advanced techniques like domain adaptation, deep learning architectures, and comprehensive datasets, I aim to enhance the accuracy and reliability of mitosis detection systems. These improvements are essential for integrating computer-aided diagnostic tools into clinical workflows, ultimately aiding pathologists in achieving faster and more consistent diagnoses.
            </p>
        </div>
    </div>
</div>


<div class="subsection" id="nuclei-instance-segmentation">
    <h3>Nuclei Instance Segmentation</h3>
    <div class="subsection-content">
        <div class="subsection-image">
            <img src="../research-areas/nuclei-instance-seg.png" alt="Nuclei Instance Segmentation">
        </div>
        <div class="subsection-text">
            <p>
                Nuclei instance segmentation is a critical task in the analysis of histopathology images, enabling the accurate identification and quantification of individual cell nuclei. This process is essential for understanding tissue morphology and aiding in disease diagnosis, particularly in cancer studies. 
            </p>
            <p>
                My MSc thesis focused on addressing the challenges in nuclei instance segmentation, including the detection of closely clustered nuclei and handling domain variations across different datasets. The study proposed novel methodologies like HR-YOLO, optimized for small object detection, and YOLO-U, a fusion of semantic segmentation and object detection techniques.
            </p>
            <p>
                This research introduced standardized training and testing protocols, ensuring fair comparisons of segmentation models across widely-used datasets such as MoNuSeg, CoNSeP, and CPM17. These contributions aim to bridge the gap between algorithmic advancements and their practical applications in medical image analysis.
            </p>
        </div>
    </div>
</div>

<div class="subsection" id="semi-supervised-learning">
    <h3>Semi-Supervised Learning</h3>
    <div class="subsection-content">
      <div class="subsection-image">
        <img src="../research-areas/semi-supervised.png" alt="Semi-Supervised Learning">
      </div>
      <div class="subsection-text">
        <p>
          Semi-supervised learning (SSL) bridges the gap between supervised and unsupervised learning by leveraging both labeled and unlabeled data during training. This approach is particularly beneficial in scenarios where acquiring labeled data is expensive or time-consuming, while unlabeled data is abundant.
        </p>
        <p>
          My research in SSL focuses on domain adaptation, tackling the challenge of training models that generalize effectively across diverse and unseen domains. This includes developing robust pseudo-labeling techniques and ensemble learning strategies to improve model reliability and performance in real-world applications.
        </p>
      </div>
    </div>
  </div>
